{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Recognition\n",
    "\n",
    "Create a script in OpenCV-Python that recognizes from a video stream (either webcam or saved video file) and frames your own face in real time! So-called \"false positives\" should be avoided, ie if your own face is missing from the video stream, the program should not point out anyone else's face.\n",
    "\n",
    "* First detect all faces in each frame, including by Haar-Cascading (Viola-Jones algorithm) \n",
    "* Apply LBPH (Low Binary Pattern Histograms) to identify your face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for video feed that it works\n",
    "\n",
    "cap = cv.VideoCapture(0) can be changed to cap = cv2.VideoCapture(\"<Video_Name_Here.mp4>\") to use a video output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Camera video feed\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Draw frame around detected faces\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('Frame',frame)\n",
    "    \n",
    "    # Quit when ESC-key is pressed\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for taking test images of your face for the dataset\n",
    "\n",
    "Uses the video feed to save images off your face. Saves them to folder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images of face for training\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "faceNumber = 0 # Incremented number for images\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "\n",
    "    #Save faces that are in frame\n",
    "    for (x,y,w,h) in faces:\n",
    "        faceNumber += 1\n",
    "        cv.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2) # Show user when images are taken\n",
    "        cv.imwrite(\"./dataSet/1.\"+str(faceNumber)+ \".jpg\", gray[y:y+h, x:x+w])\n",
    "    \n",
    "    cv.imshow('img',frame)\n",
    "    \n",
    "    # Quit when ESC-key is pressed\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for training face recognition with the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "detector= cv.CascadeClassifier(\"haarcascade_frontalface_default.xml\");\n",
    "\n",
    "def getImagesAndLabels(path):\n",
    "    #get the path of all the files in the folder\n",
    "    imagePaths=[os.path.join(path,f) for f in os.listdir(path)] \n",
    "    #create empth face list\n",
    "    faceSamples=[]\n",
    "    #create empty ID list\n",
    "    Ids=[]\n",
    "    \n",
    "    #now looping through all the image paths and loading the Ids and the images\n",
    "    for imagePath in imagePaths:\n",
    "        #loading the image and converting it to gray scale\n",
    "        pilImage=Image.open(imagePath).convert('L')\n",
    "        #Now we are converting the PIL image into numpy array\n",
    "        imageNp=np.array(pilImage,'uint8')\n",
    "        #getting the Id from the image\n",
    "        Id=int(os.path.split(imagePath)[1].split(\".\")[0])\n",
    "        # extract the face from the training image sample\n",
    "        faces=detector.detectMultiScale(imageNp)\n",
    "        #If a face is there then append that in the list as well as Id of it\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(imageNp[y:y+h,x:x+w])\n",
    "            Ids.append(Id)\n",
    "    return faceSamples,Ids\n",
    "\n",
    "\n",
    "faces,Ids = getImagesAndLabels('./dataSet')\n",
    "recognizer.train(faces, np.array(Ids))\n",
    "recognizer.save('trainner.yml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for my facial detection\n",
    "\n",
    "The conf variable should be changed depending on the trained dataset. In my case the confidence is around 50-65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.73082781343058\n",
      "75.9786332293736\n",
      "78.20384397228395\n",
      "73.32064455784209\n",
      "70.6768040284789\n",
      "76.32857425123736\n",
      "58.57258358969239\n",
      "72.28679281614338\n",
      "60.03427442453976\n",
      "64.05382775365092\n",
      "78.63257822470277\n",
      "64.03265097429184\n",
      "60.94108502456873\n",
      "63.18991774270694\n",
      "69.91379677527358\n",
      "71.23086575113805\n",
      "74.62851169667077\n",
      "76.33078638655485\n",
      "77.61512634529139\n",
      "77.17563095492882\n",
      "78.73650760673775\n",
      "77.24545594357974\n",
      "78.95213429794046\n",
      "81.62657585042933\n",
      "79.93347002328798\n",
      "82.84747091977871\n",
      "85.95488846811381\n",
      "79.53431015999561\n",
      "84.30531908342044\n",
      "81.7334031080469\n",
      "80.04065510425103\n",
      "79.24804233299209\n",
      "79.44448251356195\n",
      "80.47410325706885\n",
      "79.55008253052304\n",
      "78.40545434126216\n",
      "78.0184568642798\n",
      "81.36436325831441\n",
      "81.59586374757936\n",
      "80.18577068207883\n",
      "80.59249750854126\n",
      "79.65072435345327\n",
      "76.44342124796083\n",
      "75.43768712764064\n",
      "75.50944855236546\n",
      "68.90941192778665\n",
      "70.09069814490424\n",
      "68.02912947610926\n",
      "66.94187267462009\n",
      "67.95195987480695\n",
      "68.99529605509592\n",
      "70.10453072597043\n",
      "67.7291454987466\n",
      "67.28544614407866\n",
      "68.84566547297575\n",
      "64.27864456738558\n",
      "64.46701621068189\n",
      "66.05248147401483\n",
      "67.71822602049426\n",
      "64.88711487335084\n",
      "64.3493481080218\n",
      "63.66293953520458\n",
      "76.9729337732529\n",
      "64.73038521754764\n",
      "64.23468568096936\n",
      "74.4363439491584\n",
      "64.13073996180003\n",
      "73.76601801382776\n",
      "64.09687656152052\n",
      "65.33604229165546\n",
      "65.11542437742818\n",
      "65.76156440681278\n",
      "65.18521015218316\n",
      "67.17563618590653\n",
      "64.96388641707419\n",
      "64.76117042633196\n",
      "65.62346511671076\n",
      "65.63356382836552\n",
      "64.91405462816205\n",
      "67.23727194103614\n",
      "64.18672084559086\n",
      "73.4979192917275\n",
      "69.19405763568706\n",
      "62.67883365501411\n",
      "61.40756925815894\n",
      "62.34707600692442\n",
      "56.74301821690475\n",
      "57.171987467999564\n",
      "58.09882367358811\n",
      "56.310048253780174\n",
      "56.568965157589446\n",
      "52.36319890357913\n",
      "53.82604732902967\n",
      "54.10337890879193\n",
      "54.35228633244315\n",
      "53.85543977715954\n",
      "55.93629507882031\n",
      "54.41498108118617\n",
      "55.18103055207197\n",
      "51.15464690653689\n",
      "49.29604741275649\n",
      "52.487132513975546\n",
      "58.957962136255304\n",
      "58.453060866951375\n",
      "59.83472742321346\n",
      "59.16741350172066\n",
      "59.312259060454934\n",
      "59.64106701151699\n",
      "51.316611269173166\n",
      "51.716267682864725\n",
      "57.378441559889815\n",
      "58.35900609733465\n",
      "50.88978616540275\n",
      "57.0159992981773\n",
      "53.45927367957067\n",
      "57.03604242569431\n",
      "56.92821345098273\n",
      "55.09222844122792\n",
      "53.55839359630415\n",
      "52.9932579960067\n",
      "51.95351283519561\n",
      "52.87221416818166\n",
      "53.34327783176669\n",
      "53.91903551290791\n",
      "53.101769421926015\n",
      "52.65762449101285\n",
      "52.06734897600722\n",
      "53.42160463969326\n",
      "53.18451129437714\n",
      "53.371600773507176\n",
      "53.604794997493144\n",
      "51.908584556184685\n",
      "52.01057524049666\n",
      "52.058639350473925\n",
      "51.203271976468194\n",
      "51.240056107634125\n",
      "51.671577370760815\n",
      "52.12671483870825\n",
      "51.980388406111764\n",
      "51.95566672210183\n",
      "51.74615866768804\n",
      "50.58553394953353\n",
      "51.75983142165371\n",
      "50.62743129552843\n",
      "50.54223625847489\n",
      "50.4194807834026\n",
      "50.695055837960695\n",
      "57.51962305742648\n",
      "56.96068995729388\n"
     ]
    }
   ],
   "source": [
    "# Face detection\n",
    "\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# Video feed\n",
    "cap = cv.VideoCapture(0)\n",
    "#cap = cv.VideoCapture(\"head-pose-face-detection-male.mp4\")\n",
    "\n",
    "# Recognizer\n",
    "recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"trainner.yml\")\n",
    "id=0\n",
    "\n",
    "# Font variables\n",
    "font =  cv.FONT_HERSHEY_PLAIN\n",
    "fontSize = 1.0\n",
    "fontColor = (0, 0, 0) \n",
    "fontThickness = 1\n",
    "\n",
    "while 1:\n",
    "\n",
    "    ret, img = cap.read()\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        #cv.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        id,conf=recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        #print(100*(1-(conf)/300))\n",
    "        print(conf)\n",
    "        \n",
    "        # If confidence is under 65 the face should be a great match with Mine\n",
    "        if( id == 1 and conf<65):\n",
    "            cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv.putText(img,\"Niklas\",(int(x+(w/3)) ,y+h),font, fontSize, fontColor, fontThickness)\n",
    "\n",
    "    \n",
    "    cv.imshow('img',img)\n",
    "\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for saving the demo video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection\n",
    "\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# Video feed\n",
    "cap = cv.VideoCapture(0)\n",
    "#cap = cv.VideoCapture(\"head-pose-face-detection-male.mp4\")\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "(grabbed, frame) = cap.read() # Get camera width and height\n",
    "fshape = frame.shape\n",
    "out = cv.VideoWriter('output.mp4',fourcc, 12.0, (fshape[1],fshape[0])) # remeber to keep resolution in input and output same\n",
    "\n",
    "# Recognizer\n",
    "recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"trainner.yml\")\n",
    "id=0\n",
    "\n",
    "# Font variables\n",
    "font =  cv.FONT_HERSHEY_PLAIN\n",
    "fontSize = 1.0\n",
    "fontColor = (0, 0, 0) \n",
    "fontThickness = 1\n",
    "\n",
    "while 1:\n",
    "\n",
    "    ret, img = cap.read()\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        #cv.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        id,conf=recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        #print(100*(1-(conf)/300))\n",
    "        #print(conf)\n",
    "        \n",
    "        # If confidence is under 65 the face should be a great match with dataset\n",
    "        if( id == 1 and conf<65):\n",
    "            cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv.putText(img,\"Niklas\",(int(x+(w/3)) ,y+h),font, fontSize, fontColor, fontThickness)\n",
    "\n",
    "    \n",
    "    cv.imshow('img',img)\n",
    "    out.write(img)\n",
    "\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "out.release()        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
