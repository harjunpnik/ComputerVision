{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Recognition\n",
    "\n",
    "Create a script in OpenCV-Python that recognizes from a video stream (either webcam or saved video file) and frames your own face in real time! So-called \"false positives\" should be avoided, ie if your own face is missing from the video stream, the program should not point out anyone else's face.\n",
    "\n",
    "* First detect all faces in each frame, including by Haar-Cascading (Viola-Jones algorithm) \n",
    "* Apply LBPH (Low Binary Pattern Histograms) to identify your face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for video feed that it works\n",
    "\n",
    "cap = cv.VideoCapture(0) can be changed to cap = cv2.VideoCapture(\"<Video_Name_Here.mp4>\") to use a video output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Camera video feed\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Draw frame around detected faces\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('Frame',frame)\n",
    "    \n",
    "    # Quit when ESC-key is pressed\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for taking test images of your face for the dataset\n",
    "\n",
    "Uses the video feed to save images off your face. Saves them to folder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images of face for training\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "faceNumber = 0 # Incremented number for images\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "\n",
    "    #Save faces that are in frame\n",
    "    for (x,y,w,h) in faces:\n",
    "        faceNumber += 1\n",
    "        cv.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2) # Show user when images are taken\n",
    "        cv.imwrite(\"./dataSet/1.\"+str(faceNumber)+ \".jpg\", gray[y:y+h, x:x+w])\n",
    "    \n",
    "    cv.imshow('img',frame)\n",
    "    \n",
    "    # Quit when ESC-key is pressed\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for training face recognition with the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "detector= cv.CascadeClassifier(\"haarcascade_frontalface_default.xml\");\n",
    "\n",
    "def getImagesAndLabels(path):\n",
    "    #get the path of all the files in the folder\n",
    "    imagePaths=[os.path.join(path,f) for f in os.listdir(path)] \n",
    "    #create empth face list\n",
    "    faceSamples=[]\n",
    "    #create empty ID list\n",
    "    Ids=[]\n",
    "    \n",
    "    #now looping through all the image paths and loading the Ids and the images\n",
    "    for imagePath in imagePaths:\n",
    "        #loading the image and converting it to gray scale\n",
    "        pilImage=Image.open(imagePath).convert('L')\n",
    "        #Now we are converting the PIL image into numpy array\n",
    "        imageNp=np.array(pilImage,'uint8')\n",
    "        #getting the Id from the image\n",
    "        Id=int(os.path.split(imagePath)[1].split(\".\")[0])\n",
    "        # extract the face from the training image sample\n",
    "        faces=detector.detectMultiScale(imageNp)\n",
    "        #If a face is there then append that in the list as well as Id of it\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(imageNp[y:y+h,x:x+w])\n",
    "            Ids.append(Id)\n",
    "    return faceSamples,Ids\n",
    "\n",
    "\n",
    "faces,Ids = getImagesAndLabels('./dataSet')\n",
    "recognizer.train(faces, np.array(Ids))\n",
    "recognizer.save('trainner.yml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for my facial detection\n",
    "\n",
    "The conf variable should be changed depending on the trained dataset. In my case the confidence is around 50-65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection\n",
    "\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# Video feed\n",
    "cap = cv.VideoCapture(0)\n",
    "#cap = cv.VideoCapture(\"head-pose-face-detection-male.mp4\")\n",
    "\n",
    "# Recognizer\n",
    "recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"trainner.yml\")\n",
    "id=0\n",
    "\n",
    "# Font variables\n",
    "font =  cv.FONT_HERSHEY_PLAIN\n",
    "fontSize = 1.0\n",
    "fontColor = (0, 0, 0) \n",
    "fontThickness = 1\n",
    "\n",
    "while 1:\n",
    "\n",
    "    ret, img = cap.read()\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        #cv.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        id,conf=recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        #print(id, conf)\n",
    "        \n",
    "        # If confidence is under 80 the face should be a great match with Mine\n",
    "        if( id == 1 and conf<80):\n",
    "            cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv.putText(img,\"Niklas\",(int(x+(w/3)) ,y+h),font, fontSize, fontColor, fontThickness)\n",
    "            \n",
    "        if( id == 2 ):\n",
    "            cv.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            cv.putText(img,\"Unknown\",(int(x+(w/3)) ,y+h),font, fontSize, fontColor, fontThickness)\n",
    "\n",
    "    \n",
    "    cv.imshow('img',img)\n",
    "\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for saving the demo video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection\n",
    "\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# Video feed\n",
    "cap = cv.VideoCapture(0)\n",
    "#cap = cv.VideoCapture(\"head-pose-face-detection-male.mp4\")\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "(grabbed, frame) = cap.read() # Get camera width and height\n",
    "fshape = frame.shape\n",
    "out = cv.VideoWriter('output.mp4',fourcc, 12.0, (fshape[1],fshape[0])) # remeber to keep resolution in input and output same\n",
    "\n",
    "# Recognizer\n",
    "recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"trainner.yml\")\n",
    "id=0\n",
    "\n",
    "# Font variables\n",
    "font =  cv.FONT_HERSHEY_PLAIN\n",
    "fontSize = 1.0\n",
    "fontColor = (0, 0, 0) \n",
    "fontThickness = 1\n",
    "\n",
    "while 1:\n",
    "\n",
    "    ret, img = cap.read()\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.5, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        #cv.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        id,conf=recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        #print(100*(1-(conf)/300))\n",
    "        #print(conf)\n",
    "        \n",
    "        # If confidence is under 80 the face should be a great match with dataset\n",
    "        if( id == 1 and conf<80):\n",
    "            cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv.putText(img,\"Niklas\",(int(x+(w/3)) ,y+h),font, fontSize, fontColor, fontThickness)\n",
    "            \n",
    "        if( id == 2 ):\n",
    "            cv.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            cv.putText(img,\"Unknown\",(int(x+(w/3)) ,y+h),font, fontSize, fontColor, fontThickness)\n",
    "\n",
    "    \n",
    "    cv.imshow('img',img)\n",
    "    out.write(img)\n",
    "\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "out.release()        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
